
[![NPM](https://img.shields.io/npm/l/react)](https://github.com/marceloses/severo/blob/main/LICENSE)

<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=3399ff&height=120&section=header"/>

[![Typing SVG](https://readme-typing-svg.herokuapp.com/?color=3399ff&size=35&center=true&vCenter=true&width=1000&lines=HELLO,+MY+NAME+is+Marcelo+Severo;I'm+45+years+old;I+am+from+Itaquera,+SP;I+study+Azure+and+Cloud+Computing+at+;Be+Welcome!+:%29)](https://git.io/typing-svg) 

Construindo um Pipeline de Integração de Dados Robusto com Azure Data Factory: Do CSV na Web ao SQL Server
No cenário de dados atual, a capacidade de extrair, transformar e carregar dados de diversas fontes para um data warehouse centralizado é fundamental para obter insights valiosos. O Azure Data Factory (ADF) oferece uma plataforma poderosa e sem servidor para orquestrar e automatizar esses fluxos de dados. Neste artigo, exploraremos passo a passo como construir um pipeline no Azure Data Factory que ingere dados de um arquivo CSV hospedado na web e os carrega em uma tabela em um banco de dados SQL Server.

<div align="center">
<br><p align="centre"><b>Visitors Count</b></p>  
<p align="center"><img align="center" src="https://profile-counter.glitch.me/{marceloses}/count.svg" /></p> 
<br></div>
<div>
  Fonde de Dados Kaggle
</div>

![Azure](https://img.icons8.com/?size=100&id=81727&format=png&color=000000)&nbsp;

<img width=100% src="https://capsule-render.vercel.app/api?type=waving&color=3399ff&height=120&section=footer"/>
